# mod/about.py
about_text = (
    "<h2>About Aguida Multimodal Analyzer</h2>"
    "<p><strong>Aguida Multimodal Analyzer</strong> is a sophisticated software tool designed to integrate, analyze, "
    "and derive insights from diverse multimodal data sources, including Heart Rate monitoring, OpenFace facial analysis, "
    "Tobii eye tracking, and Dialogflow for conversational agent interactions. This versatile toolset is tailored for researchers, "
    "healthcare professionals, and developers seeking comprehensive data analysis capabilities across multiple domains.</p>"
    "<h3>Key Features:</h3>"
    "<h4>Multimodal Data Integration:</h4>"
    "<ul>"
    "<li><strong>Heart Rate Monitoring:</strong> Collects real-time or recorded heart rate data to assess physiological responses, such as stress or excitement.</li>"
    "<li><strong>OpenFace Integration:</strong> Utilizes advanced facial expression analysis, head pose estimation, and eye gaze tracking to gather detailed behavioral insights.</li>"
    "<li><strong>Tobii Eye Tracking:</strong> Captures precise eye movement and gaze behavior data for cognitive and visual attention studies.</li>"
    "<li><strong>Dialogflow Integration:</strong> Leverages natural language understanding and sentiment analysis to interpret user interactions and responses, facilitating advanced conversational agent applications.</li>"
    "</ul>"
    "<h4>Advanced Analytics and Visualization:</h4>"
    "<ul>"
    "<li><strong>Data Visualization:</strong> Provides powerful visualization tools to interpret complex multimodal data effectively, including line graphs, scatter plots, heat maps, and bar charts.</li>"
    "<li><strong>Statistical Analysis:</strong> Offers robust analytics capabilities, enabling detailed statistical analysis of multimodal data to identify patterns and correlations.</li>"
    "</ul>"
    "<h4>Customizable Analysis Modules:</h4>"
    "<ul>"
    "<li><strong>Tailored Insights:</strong> Allows customization of analysis modules to meet specific research or application needs, ensuring that insights are relevant and actionable.</li>"
    "<li><strong>Flexible Configuration:</strong> Supports the configuration of various parameters and settings to adapt to different data sources and research objectives.</li>"
    "</ul>"
    "<h4>Cross-Platform Compatibility:</h4>"
    "<ul>"
    "<li><strong>Seamless Integration:</strong> Designed to operate seamlessly across various platforms, enhancing accessibility and ease of use in diverse environments.</li>"
    "<li><strong>API Support:</strong> Facilitates integration with external systems and APIs, enabling automated data exchange and extended functionality.</li>"
    "</ul>"
    "<h4>Scalability and Flexibility:</h4>"
    "<ul>"
    "<li><strong>Scalable Analysis:</strong> Capable of handling large datasets and diverse data streams, making it suitable for both small-scale studies and extensive research projects.</li>"
    "<li><strong>Flexible Deployment:</strong> Can be deployed in different settings, including clinical, educational, and research environments, adapting to evolving needs and requirements.</li>"
    "</ul>"
    "<h3>Use Cases:</h3>"
    "<h4>Healthcare and Biomedical Research:</h4>"
    "<ul>"
    "<li><strong>Patient Monitoring:</strong> Analyze patient responses by combining physiological data with facial expressions, gaze behavior, and conversational interactions for comprehensive diagnostic and therapeutic insights.</li>"
    "<li><strong>Stress and Anxiety Studies:</strong> Evaluate stress levels by correlating heart rate data with facial expressions and conversational context.</li>"
    "</ul>"
    "<h4>Human-Computer Interaction:</h4>"
    "<ul>"
    "<li><strong>User Engagement Analysis:</strong> Study user behavior and engagement in digital environments through integrated analysis of physiological responses, gaze behavior, and conversational dynamics.</li>"
    "<li><strong>Interface Optimization:</strong> Improve user interfaces by understanding user focus and emotional states through eye tracking and facial analysis.</li>"
    "</ul>"
    "<h4>Educational and Training Applications:</h4>"
    "<ul>"
    "<li><strong>Student Engagement:</strong> Enhance learning experiences by assessing student engagement and comprehension through multimodal analysis.</li>"
    "<li><strong>Personalized Learning:</strong> Provide tailored educational content based on individual physiological and emotional responses.</li>"
    "</ul>"
    "<h3>Benefits:</h3>"
    "<ul>"
    "<li><strong>Comprehensive Insights:</strong> Gain a deeper understanding by correlating physiological metrics with facial expressions, gaze behavior, and conversational context from Dialogflow.</li>"
    "<li><strong>Efficient Data Processing:</strong> Streamline data management and analysis workflows with integrated tools and automated processes.</li>"
    "<li><strong>Enhanced User Experience:</strong> Improve the design and effectiveness of interactive systems by leveraging detailed insights into user behavior and emotional states.</li>"
    "</ul>"
    "<h3>Getting Started:</h3>"
    "<p>To leverage Aguida Multimodal Analyzer effectively, follow these steps:</p>"
    "<h4>Set Up Data Sources:</h4>"
    "<ul>"
    "<li><strong>Heart Rate Monitors:</strong> Ensure devices are calibrated and providing accurate data.</li>"
    "<li><strong>OpenFace Software:</strong> Verify camera setup and software configuration for optimal facial analysis.</li>"
    "<li><strong>Tobii Eye Trackers:</strong> Properly position and calibrate eye trackers.</li>"
    "<li><strong>Dialogflow Agents:</strong> Set up and configure conversational agents with necessary intents and training data.</li>"
    "</ul>"
    "<p><strong>Import Data:</strong> Load heart rate, eye tracking, conversational, and facial analysis data into Aguida Multimodal Analyzer.</p>"
    "<p><strong>Preprocess Data:</strong> Clean and normalize the data to ensure consistency across different data sources.</p>"
    "<h4>Feature Extraction:</h4>"
    "<ul>"
    "<li><strong>Heart Rate:</strong> Identify peaks and troughs indicating stress or excitement.</li>"
    "<li><strong>Eye Tracking:</strong> Calculate fixation durations and saccades to determine focus and attention levels.</li>"
    "<li><strong>Conversational Data:</strong> Analyze sentiment scores and response effectiveness.</li>"
    "<li><strong>Facial Analysis:</strong> Detect emotional states by examining activation levels of facial action units.</li>"
    "</ul>"
    "<p><strong>Correlation Analysis:</strong> Examine how physiological and behavioral indicators correlate with conversational dynamics.</p>"
    "<p><strong>Visualization:</strong> Generate plots and graphs to visualize data trends and correlations.</p>"
    "<p><strong>Interpretation:</strong> Derive insights from the visualizations and statistical analyses to understand participant engagement and emotional states.</p>"
)
